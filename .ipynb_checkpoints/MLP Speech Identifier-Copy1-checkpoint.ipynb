{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the necessary libraries\n",
    "import librosa \n",
    "import soundfile \n",
    "import os, glob, pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFlair - Extract features (mfcc, chroma, mel) from a sound file\n",
    "def extract_feature(file_name, mfcc, chroma, mel):\n",
    "    with soundfile.SoundFile(file_name) as sound_file:\n",
    "        X = sound_file.read(dtype=\"float32\")\n",
    "        sample_rate=sound_file.samplerate\n",
    "        if chroma:\n",
    "            stft=np.abs(librosa.stft(X))\n",
    "            result=np.array([])\n",
    "        if mfcc:\n",
    "            mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "            result=np.hstack((result, mfccs))\n",
    "#         if chroma:\n",
    "#             chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "#             result=np.hstack((result, chroma))\n",
    "        if mel:\n",
    "            mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "            result=np.hstack((result, mel))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#People and their Assigned Lables\n",
    "people={\n",
    "  '1':'Rahil',\n",
    "  '2':'Shikha',\n",
    "  '3':'Srihari',\n",
    "  '4':'Yash',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFlair - Load the data and extract features for each sound file\n",
    "def load_data(test_size=0.2):\n",
    "    x,y=[],[]\n",
    "    for file in glob.glob(\"/Users/yashdange/Desktop/BE Project/Audio/Train 2 Fixed/*.wav\"):\n",
    "        file_name=os.path.basename(file)\n",
    "        person=people[file_name.split(\"-\")[1]]\n",
    "        feature=extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
    "        x.append(feature)\n",
    "        y.append(person)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x,y=[],[]\n",
    "for file in glob.iglob(r\"/Users/yashdange/Desktop/BE Project/Audio/Train 2 Fixed/*.wav\"):\n",
    "    file_name=os.path.basename(file)\n",
    "    person=people[file_name.split(\"-\")[1]]\n",
    "    feature=extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
    "    x.append(feature)\n",
    "    y.append(person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFlair - Initialize the Multi Layer Perceptron Classifier\n",
    "model=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:542: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
      "  warnings.warn(\"Got `batch_size` less than 1 or larger than \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=0.01, batch_size=256, hidden_layer_sizes=(300,),\n",
       "              learning_rate='adaptive', max_iter=500)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DataFlair - Train the model\n",
    "model.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------record device list---------------------\n",
      "Input Device id  0  -  MacBook Pro Microphone\n",
      "Input Device id  2  -  Reincubate\n",
      "Input Device id  3  -  Microsoft Teams Audio\n",
      "Input Device id  4  -  EpocCam Microphone\n",
      "Input Device id  5  -  VB-Cable\n",
      "Input Device id  6  -  ZoomAudioDevice\n",
      "-------------------------------------------------------------\n",
      "0\n",
      "recording via index 0\n",
      "recording started\n",
      "recording stopped\n",
      "The Speaker is: ['Rahil']\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 44100\n",
    "CHUNK = 512\n",
    "RECORD_SECONDS = 5\n",
    "WAVE_OUTPUT_FILENAME = \"./Real Time Testing/Check.wav\"\n",
    "device_index = 2\n",
    "audio = pyaudio.PyAudio()\n",
    "\n",
    "print(\"----------------------record device list---------------------\")\n",
    "info = audio.get_host_api_info_by_index(0)\n",
    "numdevices = info.get('deviceCount')\n",
    "for i in range(0, numdevices):\n",
    "        if (audio.get_device_info_by_host_api_device_index(0, i).get('maxInputChannels')) > 0:\n",
    "            print(\"Input Device id \", i, \" - \", audio.get_device_info_by_host_api_device_index(0, i).get('name'))\n",
    "\n",
    "print(\"-------------------------------------------------------------\")\n",
    "\n",
    "index = int(input())\n",
    "print(\"recording via index \"+str(index))\n",
    "\n",
    "stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                rate=RATE, input=True,input_device_index = index,\n",
    "                frames_per_buffer=CHUNK)\n",
    "print (\"recording started\")\n",
    "Recordframes = []\n",
    " \n",
    "for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNK)\n",
    "    Recordframes.append(data)\n",
    "print (\"recording stopped\")\n",
    " \n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "audio.terminate()\n",
    " \n",
    "waveFile = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "waveFile.setnchannels(CHANNELS)\n",
    "waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "waveFile.setframerate(RATE)\n",
    "waveFile.writeframes(b''.join(Recordframes))\n",
    "waveFile.close()\n",
    "\n",
    "## TEST\n",
    "\n",
    "test_file = './Real Time Testing/Check.wav'\n",
    "sample = extract_feature(test_file, mfcc=True, chroma=True, mel=True)\n",
    "sample=sample.reshape(1,-1)\n",
    "\n",
    "y_pred=model.predict(sample.reshape(1,-1))\n",
    "y_pred\n",
    "\n",
    "print('The Speaker is:',y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Rahil'], dtype='<U7')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=extract_feature('./Test 2 fixed/rag.wav', mfcc=True, chroma=True, mel=True)\n",
    "test=test.reshape(1,-1)\n",
    "model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2001fc71dd2f6a11cd669c560411e621b8fd6fd914808a1d8e92020ca489f659"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
